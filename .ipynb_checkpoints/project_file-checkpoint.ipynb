{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guide Project: Profitable App Profiles for the App Store and Google Play Markets\n",
    "\n",
    "This project is built using the Dataquest introduction to data science module. It analyzes data from an App store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate apps: 1181\n"
     ]
    }
   ],
   "source": [
    "apple_opened_file = open('AppleStore.csv', encoding='utf8')\n",
    "google_opened_file = open('googleplaystore.csv', encoding='utf8')\n",
    "from csv import reader\n",
    "apple_read_file = reader(apple_opened_file)\n",
    "apple_app_data = list(apple_read_file)\n",
    "google_read_file = reader(google_opened_file)\n",
    "google_app_data = list(google_read_file)\n",
    "\n",
    "def explore_data(dataset, start, end, rows_and_columns = False):\n",
    "    dataset_slice = dataset[start:end]\n",
    "    \n",
    "    for row in dataset_slice:\n",
    "        print(row)\n",
    "        print('\\n') # Adds an empty line after each row\n",
    "        \n",
    "    if rows_and_columns:\n",
    "        print('Number of rows: ', len(dataset))\n",
    "        print('Number of columns: ', len(dataset[0]))\n",
    "\n",
    "# The first thing we do to clean the data is remove duplicates. Below, we see how many duplicates there are in the data\n",
    "duplicate_apps = []\n",
    "unique_apps = []\n",
    "\n",
    "for app in google_app_data:\n",
    "    name = app[0]\n",
    "    if name in unique_apps:\n",
    "        duplicate_apps.append(name)\n",
    "    else:\n",
    "        unique_apps.append(name)\n",
    "        \n",
    "del google_app_data[10473]\n",
    "print('Number of duplicate apps:', len(duplicate_apps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now strategically pick which of the duplicates we would like to keep in the dataset. The fourth column shows the number of ratings. It is safe to say that the entry for a given app with the most ratings is the most recent, \n",
    "so we will just keep that one.\n",
    "\n",
    "Below, we use a dictionary to store the key (app name) and its maximum number of reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of items in the dictionary: 9659\n"
     ]
    }
   ],
   "source": [
    "reviews_max = {}\n",
    "\n",
    "for row in google_app_data[1:]:\n",
    "    name = row[0]\n",
    "    n_reviews = float(row[3])\n",
    "    \n",
    "    if (name in reviews_max) and (reviews_max[name] < n_reviews):\n",
    "        reviews_max[name] = n_reviews\n",
    "        \n",
    "    if name not in reviews_max:\n",
    "        reviews_max[name] = n_reviews\n",
    "        \n",
    "print('The number of items in the dictionary:', len(reviews_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the block below, we will sweep through the whole dataset and keep only the items that meet the maximum review criterion we specified above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of our new list is: 9659\n"
     ]
    }
   ],
   "source": [
    "android_clean = []\n",
    "already_added = []\n",
    "\n",
    "for row in google_app_data[1:]:\n",
    "    name = row[0]\n",
    "    n_reviews = float(row[3])\n",
    "    \n",
    "    if (reviews_max[name] == n_reviews) and (name not in already_added):\n",
    "        android_clean.append(row)\n",
    "        already_added.append(name)\n",
    "        \n",
    "print('The length of our new list is:', len(android_clean))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning the data of non-English Apps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def english_detector(app_name):\n",
    "    counter = 0\n",
    "    for character in app_name:\n",
    "        if ord(character) > 127:\n",
    "            counter +=1\n",
    "        \n",
    "    if counter <= 3:\n",
    "        return True\n",
    "    else:\n",
    "        return False      \n",
    "    \n",
    "android_english = []\n",
    "ios_english = []\n",
    "    \n",
    "for row in android_clean:\n",
    "    app_name = row[0]\n",
    "    if english_detector(app_name):\n",
    "        android_english.append(row)\n",
    "\n",
    "for row in apple_app_data:\n",
    "    app_name = row[1]\n",
    "    if english_detector(app_name):\n",
    "        ios_english.append(row)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the free apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8863\n"
     ]
    }
   ],
   "source": [
    "android_free = []\n",
    "\n",
    "for row in android_english:\n",
    "    app_price = row[6]\n",
    "    if app_price == 'Free':\n",
    "        android_free.append(row)\n",
    "print(len(android_free))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to operationalize the dataset to see how we can determine which apps will be bring us the most profit.\n",
    "\n",
    "With that in mind, we should use 'Rating', 'Reviews', and 'Installs' to see which will be successful in the future.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAMILY : 18.898792733837304\n",
      "GAME : 9.725826469592688\n",
      "TOOLS : 8.462146000225657\n",
      "BUSINESS : 4.592124562789123\n",
      "LIFESTYLE : 3.9038700214374367\n",
      "PRODUCTIVITY : 3.8925871601038025\n",
      "FINANCE : 3.7007785174320205\n",
      "MEDICAL : 3.5315355974275078\n",
      "SPORTS : 3.396141261423897\n",
      "PERSONALIZATION : 3.317161232088458\n",
      "COMMUNICATION : 3.2381812027530184\n",
      "HEALTH_AND_FITNESS : 3.0802211440821394\n",
      "PHOTOGRAPHY : 2.944826808078529\n",
      "NEWS_AND_MAGAZINES : 2.798149610741284\n",
      "SOCIAL : 2.6627552747376737\n",
      "TRAVEL_AND_LOCAL : 2.335552296062281\n",
      "SHOPPING : 2.245289405393208\n",
      "BOOKS_AND_REFERENCE : 2.1437436533904997\n",
      "DATING : 1.8616721200496444\n",
      "VIDEO_PLAYERS : 1.7939749520478394\n",
      "MAPS_AND_NAVIGATION : 1.399074805370642\n",
      "FOOD_AND_DRINK : 1.241114746699763\n",
      "EDUCATION : 1.1621347173643235\n",
      "ENTERTAINMENT : 0.9590432133589079\n",
      "LIBRARIES_AND_DEMO : 0.9364774906916393\n",
      "AUTO_AND_VEHICLES : 0.9251946293580051\n",
      "HOUSE_AND_HOME : 0.8236488773552973\n",
      "WEATHER : 0.8010831546880289\n",
      "EVENTS : 0.7108202640189552\n",
      "PARENTING : 0.6544059573507841\n",
      "ART_AND_DESIGN : 0.6431230960171499\n",
      "COMICS : 0.6205573733498815\n",
      "BEAUTY : 0.5979916506826132\n"
     ]
    }
   ],
   "source": [
    "# Create a frequency table in the form of a dictionary. Return items as percentages.\n",
    "def freq_table(dataset, index):\n",
    "    frequency_table = {}\n",
    "    total = 0\n",
    "    \n",
    "    for row in dataset:\n",
    "        total += 1\n",
    "        data_item = row[index]\n",
    "        if data_item in frequency_table:\n",
    "            frequency_table[data_item] += 1\n",
    "        else:\n",
    "            frequency_table[data_item] = 1\n",
    "    \n",
    "    percentage_table = {}\n",
    "    for key in frequency_table:\n",
    "        percentage = (frequency_table[key]/total) * 100\n",
    "        percentage_table[key] = percentage\n",
    "    \n",
    "    return percentage_table\n",
    "\n",
    "\n",
    "\n",
    "# Create a display table in the form of a tuple from the frequency dictionary above\n",
    "def display_table(dataset, index):\n",
    "    table = freq_table(dataset, index)\n",
    "    table_display = []\n",
    "    for key in table:\n",
    "        key_val_as_tuple = (table[key], key)\n",
    "        table_display.append(key_val_as_tuple)\n",
    "\n",
    "    table_sorted = sorted(table_display, reverse = True)\n",
    "    for entry in table_sorted:\n",
    "        print(entry[1], ':', entry[0])\n",
    "\n",
    "display_table(android_free, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category\n",
      "Genres\n"
     ]
    }
   ],
   "source": [
    "print(google_app_data[0][1])\n",
    "print(google_app_data[0][9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
